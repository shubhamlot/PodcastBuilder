{"ast":null,"code":"var _jsxFileName = \"D:\\\\ProjectFolder\\\\Podcast Builder\\\\frontend\\\\src\\\\componets2\\\\Reactmic.js\",\n    _s = $RefreshSig$();\n\n// import { ReactMic } from 'react-mic';\n// import React, { useContext, useEffect, useState } from 'react' \n// import {AudioProcess} from './AudioProcess'\n// import {gql, useMutation} from '@apollo/client';\n// import {Button, Container, Grid, Icon, IconButton, ThemeProvider} from '@material-ui/core'\n// import { makeStyles } from '@material-ui/core/styles';\n// import { Redirect, useParams } from 'react-router';\n// import AuthContext from '../context/auth-context'\n// import { Link } from 'react-router-dom';\n// import {saveAs} from 'file-saver'\n// import { Done, Mic, PlayArrow, Stop } from '@material-ui/icons';\n// import Recorder from 'recorder-js';\n// var toWav = require('audiobuffer-to-wav')\n// const UPLOAD_FILE = gql`\n//   mutation UploadFile($file:Upload!,$roomid:String,$speaker:String){\n//       UploadFile(file:$file,roomid:$roomid,speaker:$speaker)\n//   }\n// `\n// const useStyles = makeStyles((theme)=>({\n//   buttonroot:{\n//     display:'flex',\n//     width:'100%',\n//   },\n//   startbutton:{\n//     flex:1,\n//     color:'blue'\n//   },\n//   stopbutton:{\n//     flex:1,\n//     color:\"red\"\n//   },\n//   donebutton:{\n//     textDecoration:'none'\n//   },\n//   container:{\n//     padding:10\n//   },\n//   control:{\n//     display:\"flex\"\n//   },\n//   icon:{\n//     // flex:1,\n//     textAlign:\"center\",\n//     color:\"#000000\"\n//   },\n//   iconmic:{\n//     // flex:1,\n//     textAlign:\"center\",\n//     color:\"red\"\n//   },\n//   gif:{\n//     flex:1,\n//     justifyItems:\"contain\"\n//   }\n// }))\n// export default function Reactmic(props){\n//   const auth = useContext(AuthContext)\n//   const audioContext =  new (window.AudioContext || window.webkitAudioContext)();\n//   const recorder = new Recorder(audioContext, {\n//       // An array of 255 Numbers\n//       // You can use this to visualize the audio stream\n//       // If you use react, check out react-wave-stream\n//       // onAnalysed: data => console.log(data),\n//     });\n//   const classes = useStyles();\n//     const [state,setState] = useState({\n//         recording:false,\n//     })\n//     const [file,getFile] = useState(null)\n//     const[uploadFile] = useMutation(UPLOAD_FILE,{\n//         onCompleted: data => console.log(data),\n//       })\n//   const { room } = useParams()\n//   navigator.mediaDevices.getUserMedia({audio: true})\n//   .then(stream => recorder.init(stream))\n//   .catch(err => console.log('Uh oh... unable to get stream...', err));\n//   const onStart=()=>{\n//     recorder.start()\n//     .then(() => {setState({recording:true})\n//     console.log(\"start\")});\n//   }\n//   const onStop=()=> {\n//     if(state.recording){\n//     recorder.stop()\n//     .then(({blob, buffer}) => {\n//       setState({recording:false});\n//       console.log(blob)\n//       getFile(blob)\n//     });\n//  // if(file ===null || roomid === null || speaker === null) console.log(state.recording)\n//  let speaker=auth.userId\n//  if(!auth.userId) speaker=\"\"\n//    uploadFile({variables:{file:file,roomid:room,speaker:speaker}})\n//   }\n//   }\n//     return (\n//         // <div>\n//         // {/* <button onClick={startRecording} type=\"button\">Start</button>\n//         // <button onClick={stopRecording} type=\"button\">Stop</button> */}\n//         // <div className={classes.buttonroot}>\n//         // <Button className={classes.startbutton} onClick={startRecording}>Start</Button>\n//         // <Button className={classes.stopbutton} onClick={stopRecording}>Stop</Button>\n//         // <Button className={classes.donebutton} >\n//         // <Link className={classes.donebutton} to={`roomID=${room}/editpodcast`} >Done</Link>\n//         // </Button>\n//         // </div>\n//         // </div>\n//         <div className={classes.container}>\n//           <div className={classes.control}>\n//           <div className={classes.gif}>\n//           {/* <ReactMic\n//           width=\"250\"\n//           height=\"50\"\n//           visualSetting=\"frequencyBars\"\n//           record={state.recording}\n//           onStop={onStop}\n//           strokeColor=\"#ffffff\"\n//           backgroundColor=\"#1976d2\"\n//           bitRate={256000}     \n//           sampleRate={96000}\n//           timeSlice={3000} \n//           minetype=\"audio/wav\"\n//           /> */}\n//           </div>\n//             <Button \n//             className={ classes.icon\n//             } \n//             onClick={ onStart}>\n//                 <Mic/>\n//             </Button>\n//             <Button \n//             className={ classes.iconmic\n//             } \n//             onClick={onStop}>\n//                 <Mic/>\n//             </Button>\n//             <Button className={classes.icon}>\n//               <Link className={classes.donebutton} to={`roomID=${room}/editpodcast`}>\n//                 <Done/>\n//               </Link>\n//             </Button>\n//           </div>\n//         </div>\n//     )\n// }\nimport { useState } from 'react';\nimport Recorder from 'recorder-js';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nexport default function Test() {\n  _s();\n\n  const audioContext = new (window.AudioContext || window.webkitAudioContext)();\n  const recorder = new Recorder(audioContext, {// An array of 255 Numbers\n    // You can use this to visualize the audio stream\n    // If you use react, check out react-wave-stream\n    // onAnalysed: data => console.log(data),\n  });\n  let isRecording = false;\n  const [state, setState] = useState(null);\n  navigator.mediaDevices.getUserMedia({\n    audio: true\n  }).then(stream => recorder.init(stream)).catch(err => console.log('Uh oh... unable to get stream...', err));\n\n  const startRecording = () => {\n    recorder.start().then(() => isRecording = true);\n    console.log(\"start\");\n  };\n\n  const stopRecording = () => {\n    recorder.stop().then(({\n      blob,\n      buffer\n    }) => {\n      setState(blob);\n      console.log(\"stop\"); // buffer is an AudioBuffer\n    });\n  };\n\n  const download = () => {\n    console.log(state); // Recorder.download(state, 'my-audio-file'); // downloads a .wav file\n  };\n\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: [/*#__PURE__*/_jsxDEV(\"button\", {\n      onClick: startRecording,\n      children: \"start\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 248,\n      columnNumber: 11\n    }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n      onClick: stopRecording,\n      children: \"stop\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 249,\n      columnNumber: 11\n    }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n      onClick: download,\n      children: \"download\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 250,\n      columnNumber: 11\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 247,\n    columnNumber: 7\n  }, this);\n}\n\n_s(Test, \"GjdxGzq9XwV1VYLHhI8SB8teZlY=\");\n\n_c = Test;\n\nvar _c;\n\n$RefreshReg$(_c, \"Test\");","map":{"version":3,"sources":["D:/ProjectFolder/Podcast Builder/frontend/src/componets2/Reactmic.js"],"names":["useState","Recorder","Test","audioContext","window","AudioContext","webkitAudioContext","recorder","isRecording","state","setState","navigator","mediaDevices","getUserMedia","audio","then","stream","init","catch","err","console","log","startRecording","start","stopRecording","stop","blob","buffer","download"],"mappings":";;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAGA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AAEA;AACA;AAEA;AAEA;AAEA;AACA;AACA;AAIA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AAGA;AAGA;AAGA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AAGA;AACA;AAGA;AAEA;AAUA,SAASA,QAAT,QAAyB,OAAzB;AACA,OAAOC,QAAP,MAAqB,aAArB;;AAGA,eAAe,SAASC,IAAT,GAAe;AAAA;;AAC1B,QAAMC,YAAY,GAAI,KAAKC,MAAM,CAACC,YAAP,IAAuBD,MAAM,CAACE,kBAAnC,GAAtB;AACA,QAAMC,QAAQ,GAAG,IAAIN,QAAJ,CAAaE,YAAb,EAA2B,CACxC;AACA;AACA;AACA;AAJwC,GAA3B,CAAjB;AAOE,MAAIK,WAAW,GAAG,KAAlB;AAEA,QAAM,CAACC,KAAD,EAAOC,QAAP,IAAmBV,QAAQ,CAAC,IAAD,CAAjC;AAGAW,EAAAA,SAAS,CAACC,YAAV,CAAuBC,YAAvB,CAAoC;AAACC,IAAAA,KAAK,EAAE;AAAR,GAApC,EACHC,IADG,CACEC,MAAM,IAAIT,QAAQ,CAACU,IAAT,CAAcD,MAAd,CADZ,EAEHE,KAFG,CAEGC,GAAG,IAAIC,OAAO,CAACC,GAAR,CAAY,kCAAZ,EAAgDF,GAAhD,CAFV;;AAKJ,QAAMG,cAAc,GAAC,MAAI;AAEvBf,IAAAA,QAAQ,CAACgB,KAAT,GACGR,IADH,CACQ,MAAMP,WAAW,GAAG,IAD5B;AAEEY,IAAAA,OAAO,CAACC,GAAR,CAAY,OAAZ;AACH,GALD;;AAOA,QAAMG,aAAa,GAAC,MAAI;AACtBjB,IAAAA,QAAQ,CAACkB,IAAT,GACGV,IADH,CACQ,CAAC;AAACW,MAAAA,IAAD;AAAOC,MAAAA;AAAP,KAAD,KAAoB;AACxBjB,MAAAA,QAAQ,CAACgB,IAAD,CAAR;AACAN,MAAAA,OAAO,CAACC,GAAR,CAAY,MAAZ,EAFwB,CAGxB;AACD,KALH;AAMD,GAPD;;AAQA,QAAMO,QAAQ,GAAC,MAAI;AACjBR,IAAAA,OAAO,CAACC,GAAR,CAAYZ,KAAZ,EADiB,CAEjB;AACD,GAHD;;AAMA,sBACI;AAAA,4BACI;AAAQ,MAAA,OAAO,EAAEa,cAAjB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YADJ,eAEI;AAAQ,MAAA,OAAO,EAAEE,aAAjB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAFJ,eAGI;AAAQ,MAAA,OAAO,EAAEI,QAAjB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAHJ;AAAA;AAAA;AAAA;AAAA;AAAA,UADJ;AAQD;;GAhDuB1B,I;;KAAAA,I","sourcesContent":["// import { ReactMic } from 'react-mic';\r\n// import React, { useContext, useEffect, useState } from 'react' \r\n// import {AudioProcess} from './AudioProcess'\r\n// import {gql, useMutation} from '@apollo/client';\r\n// import {Button, Container, Grid, Icon, IconButton, ThemeProvider} from '@material-ui/core'\r\n// import { makeStyles } from '@material-ui/core/styles';\r\n// import { Redirect, useParams } from 'react-router';\r\n// import AuthContext from '../context/auth-context'\r\n// import { Link } from 'react-router-dom';\r\n// import {saveAs} from 'file-saver'\r\n// import { Done, Mic, PlayArrow, Stop } from '@material-ui/icons';\r\n// import Recorder from 'recorder-js';\r\n\r\n// var toWav = require('audiobuffer-to-wav')\r\n// const UPLOAD_FILE = gql`\r\n//   mutation UploadFile($file:Upload!,$roomid:String,$speaker:String){\r\n//       UploadFile(file:$file,roomid:$roomid,speaker:$speaker)\r\n//   }\r\n// `\r\n\r\n\r\n// const useStyles = makeStyles((theme)=>({\r\n//   buttonroot:{\r\n//     display:'flex',\r\n//     width:'100%',\r\n//   },\r\n//   startbutton:{\r\n//     flex:1,\r\n//     color:'blue'\r\n//   },\r\n//   stopbutton:{\r\n//     flex:1,\r\n//     color:\"red\"\r\n//   },\r\n//   donebutton:{\r\n   \r\n//     textDecoration:'none'\r\n//   },\r\n  \r\n//   container:{\r\n//     padding:10\r\n//   },\r\n//   control:{\r\n//     display:\"flex\"\r\n//   },\r\n//   icon:{\r\n//     // flex:1,\r\n//     textAlign:\"center\",\r\n//     color:\"#000000\"\r\n//   },\r\n//   iconmic:{\r\n//     // flex:1,\r\n//     textAlign:\"center\",\r\n//     color:\"red\"\r\n//   },\r\n//   gif:{\r\n//     flex:1,\r\n//     justifyItems:\"contain\"\r\n//   }\r\n\r\n// }))\r\n\r\n\r\n// export default function Reactmic(props){\r\n\r\n\r\n//   const auth = useContext(AuthContext)\r\n//   const audioContext =  new (window.AudioContext || window.webkitAudioContext)();\r\n//   const recorder = new Recorder(audioContext, {\r\n//       // An array of 255 Numbers\r\n//       // You can use this to visualize the audio stream\r\n//       // If you use react, check out react-wave-stream\r\n//       // onAnalysed: data => console.log(data),\r\n//     });\r\n\r\n  \r\n\r\n//   const classes = useStyles();\r\n  \r\n//     const [state,setState] = useState({\r\n//         recording:false,\r\n        \r\n//     })\r\n\r\n//     const [file,getFile] = useState(null)\r\n\r\n//     const[uploadFile] = useMutation(UPLOAD_FILE,{\r\n//         onCompleted: data => console.log(data),\r\n//       })\r\n \r\n  \r\n  \r\n//   const { room } = useParams()\r\n\r\n//   navigator.mediaDevices.getUserMedia({audio: true})\r\n//   .then(stream => recorder.init(stream))\r\n//   .catch(err => console.log('Uh oh... unable to get stream...', err));\r\n  \r\n//   const onStart=()=>{\r\n   \r\n//     recorder.start()\r\n//     .then(() => {setState({recording:true})\r\n//     console.log(\"start\")});\r\n    \r\n//   }\r\n//   const onStop=()=> {\r\n\r\n//     if(state.recording){\r\n//     recorder.stop()\r\n//     .then(({blob, buffer}) => {\r\n//       setState({recording:false});\r\n//       console.log(blob)\r\n//       getFile(blob)\r\n      \r\n//     });\r\n//  // if(file ===null || roomid === null || speaker === null) console.log(state.recording)\r\n//  let speaker=auth.userId\r\n//  if(!auth.userId) speaker=\"\"\r\n//    uploadFile({variables:{file:file,roomid:room,speaker:speaker}})\r\n    \r\n//   }\r\n   \r\n  \r\n//   }\r\n \r\n\r\n//     return (\r\n      \r\n        \r\n//         // <div>\r\n       \r\n//         // {/* <button onClick={startRecording} type=\"button\">Start</button>\r\n//         // <button onClick={stopRecording} type=\"button\">Stop</button> */}\r\n//         // <div className={classes.buttonroot}>\r\n//         // <Button className={classes.startbutton} onClick={startRecording}>Start</Button>\r\n//         // <Button className={classes.stopbutton} onClick={stopRecording}>Stop</Button>\r\n//         // <Button className={classes.donebutton} >\r\n//         // <Link className={classes.donebutton} to={`roomID=${room}/editpodcast`} >Done</Link>\r\n//         // </Button>\r\n//         // </div>\r\n//         // </div>\r\n\r\n//         <div className={classes.container}>\r\n//           <div className={classes.control}>\r\n//           <div className={classes.gif}>\r\n//           {/* <ReactMic\r\n//           width=\"250\"\r\n//           height=\"50\"\r\n//           visualSetting=\"frequencyBars\"\r\n//           record={state.recording}\r\n//           onStop={onStop}\r\n//           strokeColor=\"#ffffff\"\r\n//           backgroundColor=\"#1976d2\"\r\n//           bitRate={256000}     \r\n//           sampleRate={96000}\r\n//           timeSlice={3000} \r\n//           minetype=\"audio/wav\"\r\n//           /> */}\r\n//           </div>\r\n           \r\n//             <Button \r\n//             className={ classes.icon\r\n//             } \r\n//             onClick={ onStart}>\r\n             \r\n//                 <Mic/>\r\n             \r\n//             </Button>\r\n//             <Button \r\n//             className={ classes.iconmic\r\n//             } \r\n//             onClick={onStop}>\r\n             \r\n//                 <Mic/>\r\n             \r\n//             </Button>\r\n//             <Button className={classes.icon}>\r\n//               <Link className={classes.donebutton} to={`roomID=${room}/editpodcast`}>\r\n             \r\n//                 <Done/>\r\n              \r\n//               </Link>\r\n//             </Button>\r\n            \r\n\r\n//           </div>\r\n//         </div>\r\n\r\n      \r\n//     )\r\n  \r\n// }\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nimport { useState } from 'react';\r\nimport Recorder from 'recorder-js';\r\n\r\n\r\nexport default function Test(){\r\n    const audioContext =  new (window.AudioContext || window.webkitAudioContext)();\r\n    const recorder = new Recorder(audioContext, {\r\n        // An array of 255 Numbers\r\n        // You can use this to visualize the audio stream\r\n        // If you use react, check out react-wave-stream\r\n        // onAnalysed: data => console.log(data),\r\n      });\r\n\r\n      let isRecording = false;\r\n      \r\n      const [state,setState] = useState(null)\r\n\r\n\r\n      navigator.mediaDevices.getUserMedia({audio: true})\r\n  .then(stream => recorder.init(stream))\r\n  .catch(err => console.log('Uh oh... unable to get stream...', err));\r\n\r\n\r\n  const startRecording=()=>{\r\n      \r\n    recorder.start()\r\n      .then(() => isRecording = true);\r\n      console.log(\"start\")\r\n  }\r\n\r\n  const stopRecording=()=>{\r\n    recorder.stop()\r\n      .then(({blob, buffer}) => {\r\n        setState(blob);\r\n        console.log(\"stop\")\r\n        // buffer is an AudioBuffer\r\n      });\r\n  }\r\n  const download=()=>{\r\n    console.log(state)\r\n    // Recorder.download(state, 'my-audio-file'); // downloads a .wav file\r\n  }\r\n\r\n\r\n  return(\r\n      <div>\r\n          <button onClick={startRecording}>start</button>\r\n          <button onClick={stopRecording}>stop</button>\r\n          <button onClick={download}>download</button>\r\n\r\n      </div>\r\n  )\r\n}"]},"metadata":{},"sourceType":"module"}